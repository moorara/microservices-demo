# https://docs.fluentd.org
# https://docs.fluentd.org/v1.0/articles/life-of-a-fluentd-event
# https://docs.fluentd.org/v1.0/articles/config-file
# https://docs.fluentd.org/v1.0/articles/logging


# Fluentd logs in json too
<system>
  log_level debug
  <log>
    format json
  </log>
</system>

# https://docs.fluentd.org/v1.0/articles/in_forward
# Listen to a TCP socket to receive the event stream. It also listens to an UDP socket.
<source>
  @type forward
  bind 0.0.0.0
  port 24224
</source>

# https://docs.fluentd.org/v1.0/articles/filter_grep
# Filter logs in json format and reject non-json logs
<filter docker.**>
  @type grep
  <regexp>
    key log
    pattern ^{.*}$
  </regexp>
</filter>

# https://docs.fluentd.org/v1.0/articles/filter_parser
# https://docs.fluentd.org/v1.0/articles/parser_json
# Parse logs as json and add them to event record
# "reserve_time" keeps the fluentd event time
<filter docker.**>
  @type parser
  key_name log
  reserve_time true
  reserve_data true
  <parse>
    @type json
  </parse>
</filter>

# https://docs.fluentd.org/v1.0/articles/filter_record_transformer
# https://docs.fluentd.org/v1.0/articles/api-plugin-helper-record_accessor
# Mutate Traefik logs in order to make them consistent with other logs
# Traefik logs "time" in RFC3339 which fluentd parser cannot parse it.
# So, we need to make sure Traefik logs include "timestamp" with same format as other logs.
<filter docker.traefik.**>
  @type record_transformer
  enable_ruby true
  remove_keys msg
  <record>
    message ${record["msg"]}
    timestamp ${time.strftime("%Y-%m-%dT%H:%M:%S%z")}
  </record>
</filter>

# https://docs.fluentd.org/v1.0/articles/filter_record_transformer
# Remove keys from event record and construct new keys
<filter docker.**>
  @type record_transformer
  enable_ruby true
  remove_keys log
  <record>
    environment local
    region local
    container_image ${tag_parts[2,10].join(".")}
  </record>
</filter>

# https://docs.fluentd.org/v1.0/articles/out_copy
# https://docs.fluentd.org/v1.0/articles/out_stdout
# https://docs.fluentd.org/v1.0/articles/out_elasticsearch
# https://docs.fluentd.org/v1.0/articles/buffer-plugin-overview
<match docker.**>
  @type copy
  <store>
    @type stdout
  </store>
  <store>
    @type elasticsearch
    host elasticsearch
    port 9200
    index_name fluentd
    include_tag_key true
    include_timestamp true
    <buffer>
      @type memory
      flush_interval 5s
    </buffer>
  </store>
</match>
